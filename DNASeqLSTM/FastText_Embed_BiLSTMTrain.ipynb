{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.functional\")\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Initialization amd Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "# import keras as K\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Activation, Permute\n",
    "from keras.layers import LSTM, Dropout, CuDNNGRU, Bidirectional, Embedding \n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from keras.optimizers import RMSprop, Adam, Adagrad, Adadelta, SGD\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Convolution1D, Conv1D, \\\n",
    "                         MaxPool1D, Lambda, GlobalMaxPooling1D, GlobalAveragePooling1D, \\\n",
    "                         BatchNormalization, Activation, AveragePooling1D, Concatenate, concatenate\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, \\\n",
    "                                    KFold, StratifiedKFold, RepeatedKFold, RepeatedStratifiedKFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import math        \n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import heapq\n",
    "import seaborn as sns\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with K.tf.device('/GPU:0'):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "    session = tf.Session(config=config)\n",
    "    K.set_session(session)\n",
    "#     set_gpu_option(\"0\", 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "curruser = os.environ.get('USER')\n",
    "sys.path.insert(0, './src/')\n",
    "\n",
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import csv\n",
    "\n",
    "from LSTMPreProc import preprocIO\n",
    "from Bio import SeqIO\n",
    "import smart_open\n",
    "# from bpe import Encoder\n",
    "import sentencepiece as spm\n",
    "# from tokenizers import CharBPETokenizer, ByteLevelBPETokenizer, SentencePieceBPETokenizer\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pylab import rcParams\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 12, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel, KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.utils import tokenize\n",
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dnaSegPath = ('./data/dnaseg/mart_export.txt')\n",
    "# prep = preprocIO()\n",
    "# seqArr = []\n",
    "# for seq in tqdm_notebook(prep.streamFastaIO(dnaSegPath)):\n",
    "#      seqArr+=[seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    plt.plot(history['acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    \n",
    "def confusion_matrix_heatmap(y_true, y_pred):\n",
    "    '''\n",
    "    Построение Confusion matrix (матрицы ошибок)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test: pandas.Series, numpy.array\n",
    "        Целевая для обучающего набора\n",
    "    y_pred: pandas.Series, numpy.array\n",
    "        Значения целевой переменной, предсказанные классификатором\n",
    "    '''\n",
    "    rcParams['figure.figsize'] = 6, 4\n",
    "    sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d', cmap='Greens')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained BPE Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"models/BPE/sentpbpe.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁',\n",
       " 'ATGG',\n",
       " 'AG',\n",
       " 'ATCCC',\n",
       " 'TG',\n",
       " 'TGCC',\n",
       " 'TG',\n",
       " 'TGC',\n",
       " 'AGCC',\n",
       " 'G',\n",
       " 'TC',\n",
       " 'T',\n",
       " 'TGGC',\n",
       " 'TGC',\n",
       " 'GCC',\n",
       " 'GC',\n",
       " 'GCC',\n",
       " 'TC',\n",
       " 'GGCC',\n",
       " 'CC',\n",
       " 'G',\n",
       " 'TTG',\n",
       " 'CCC',\n",
       " 'GG',\n",
       " 'AC',\n",
       " 'TTTC',\n",
       " 'GGC',\n",
       " 'G',\n",
       " 'CCC',\n",
       " 'GG',\n",
       " 'AC',\n",
       " 'GCC',\n",
       " 'TC',\n",
       " 'TTTG',\n",
       " 'ACC',\n",
       " 'AGC',\n",
       " 'GC',\n",
       " 'TTC',\n",
       " 'GGC',\n",
       " 'G',\n",
       " 'AGG',\n",
       " 'GGC',\n",
       " 'TGC',\n",
       " 'TGG',\n",
       " 'AGGCC',\n",
       " 'G',\n",
       " 'AGC',\n",
       " 'TGGC',\n",
       " 'TGC',\n",
       " 'GC',\n",
       " 'TC',\n",
       " 'TGCC',\n",
       " 'CC',\n",
       " 'ACC',\n",
       " 'ACGC',\n",
       " 'TC',\n",
       " 'GCC',\n",
       " 'CCC',\n",
       " 'TAC',\n",
       " 'TACC',\n",
       " 'TGC',\n",
       " 'GC',\n",
       " 'GC',\n",
       " 'ACCC',\n",
       " 'AGCG',\n",
       " 'TGGC',\n",
       " 'GC',\n",
       " 'TGCCC',\n",
       " 'G',\n",
       " 'TCG',\n",
       " 'CCC',\n",
       " 'AGG',\n",
       " 'TGCC',\n",
       " 'G',\n",
       " 'ACGG',\n",
       " 'ACCCC',\n",
       " 'GGCC',\n",
       " 'AC',\n",
       " 'TT',\n",
       " 'TTC',\n",
       " 'GG',\n",
       " 'TGC',\n",
       " 'TGC',\n",
       " 'T',\n",
       " 'AGAC',\n",
       " 'G',\n",
       " 'TG',\n",
       " 'AAGC',\n",
       " 'AC',\n",
       " 'TTC',\n",
       " 'TC',\n",
       " 'GCC',\n",
       " 'GG',\n",
       " 'AGGAA',\n",
       " 'AT',\n",
       " 'TGC',\n",
       " 'TGTC',\n",
       " 'AAGG',\n",
       " 'TGG',\n",
       " 'TGGGC',\n",
       " 'G',\n",
       " 'AAC',\n",
       " 'ACG',\n",
       " 'TGG',\n",
       " 'AGG',\n",
       " 'TGC',\n",
       " 'ACGC',\n",
       " 'GC',\n",
       " 'GCC',\n",
       " 'ACG',\n",
       " 'AGG',\n",
       " 'AGCG',\n",
       " 'CCC',\n",
       " 'GG',\n",
       " 'ATG',\n",
       " 'AGC',\n",
       " 'ACGG',\n",
       " 'ATTC',\n",
       " 'G',\n",
       " 'TC',\n",
       " 'GC',\n",
       " 'GC',\n",
       " 'GCG',\n",
       " 'AG',\n",
       " 'TTCC',\n",
       " 'ACCG',\n",
       " 'TC',\n",
       " 'GC',\n",
       " 'TACC',\n",
       " 'GCC',\n",
       " 'TGCC',\n",
       " 'GCC',\n",
       " 'TGGC',\n",
       " 'G',\n",
       " 'TGG',\n",
       " 'ATCC',\n",
       " 'GGC',\n",
       " 'TGCC',\n",
       " 'G',\n",
       " 'TG',\n",
       " 'ACG',\n",
       " 'TCC',\n",
       " 'GC',\n",
       " 'GC',\n",
       " 'TG',\n",
       " 'TCC',\n",
       " 'CCC',\n",
       " 'G',\n",
       " 'AGGGC',\n",
       " 'G',\n",
       " 'TCC',\n",
       " 'TG',\n",
       " 'TCC',\n",
       " 'ATCC',\n",
       " 'AGGCC',\n",
       " 'GC',\n",
       " 'ACC',\n",
       " 'AGCG',\n",
       " 'TC',\n",
       " 'GG',\n",
       " 'CCC',\n",
       " 'AGGCC',\n",
       " 'CC',\n",
       " 'ACC',\n",
       " 'GCC',\n",
       " 'AGCC',\n",
       " 'GC',\n",
       " 'AGCC',\n",
       " 'AAG',\n",
       " 'TAG']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_str = seqArr[0]\n",
    "sp.EncodeAsPieces(_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Gensim FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterator for FastText train\n",
    "class GensimCorporaIter(object):\n",
    "    def __init__(self, pathtofile, sp):\n",
    "        self.pathtofile = pathtofile\n",
    "        self.sp = sp\n",
    "    def __iter__(self):\n",
    "        path = datapath(self.pathtofile)  # absolute path to corpus\n",
    "        with open(path, 'r', encoding='utf8', errors = 'ignore') as fin:\n",
    "            for line in fin:\n",
    "                line = line.rstrip('\\n')\n",
    "                yield list(self.sp.EncodeAsPieces(line))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnaSegPathPost = os.path.join(os.getcwd(),'data/dnaseg/mart_export_proc.txt')\n",
    "# GensimIter = GensimCorporaIter(dnaSegPathPost, sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_gensim = FT_gensim(size=300, window=5, min_count=1, sg=1, negative=15, \n",
    "                         min_n=1, max_n=6, word_ngrams=1, workers=10)\n",
    "model_gensim.build_vocab(sentences = GensimCorporaIter(dnaSegPathPost, sp))\n",
    "model_gensim.train(sentences=GensimCorporaIter(dnaSegPathPost, sp), \n",
    "                   total_examples=model_gensim.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/fasttext/ft_model.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw2vec = './models/fasttext/ft_300.vec'\n",
    "model_gensim.wv.save_word2vec_format(fw2vec)\n",
    "joblib.dump(model_gensim, './models/fasttext/ft_model.pkl', compress=('gzip',9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw2vec = './models/fasttext/ft_300.vec'\n",
    "w2vec = KeyedVectors.load_word2vec_format(fw2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ATG', 0.5819699764251709),\n",
       " ('AAAA', 0.5773802399635315),\n",
       " ('TGAC', 0.570457398891449),\n",
       " ('AACC', 0.5695433020591736),\n",
       " ('TGGCC', 0.5683084726333618),\n",
       " ('TGGGG', 0.5679406523704529),\n",
       " ('AAAC', 0.5669651031494141),\n",
       " ('AAGCC', 0.5583610534667969),\n",
       " ('ATGC', 0.5575288534164429),\n",
       " ('AAC', 0.5545167922973633)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gensim.wv.similar_by_word('A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embedding Matrix: `(Token's Id, Weighted Vector)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import OrderedDict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_words2vec(pathtofile, pathtoexport, sp, fasttext_model):\n",
    "    corpora = []\n",
    "    result = []  \n",
    "    print('Tokenize sequense corpora from file-->')\n",
    "    path = datapath(pathtofile)  # absolute path to corpus\n",
    "    with open(path, 'r', encoding='utf8', errors = 'ignore') as fin:\n",
    "        for line in tqdm_notebook(fin):\n",
    "            line = line.rstrip('\\n')\n",
    "            corpora.append(list(sp.EncodeAsPieces(line))[1:])\n",
    "    \n",
    "    maxlen = max(map(len, corpora))\n",
    "    \n",
    "    print(\"max tokens len: {}\".format(maxlen))\n",
    "    \n",
    "    print(\"Build BOW and calculate TFIDF...\")\n",
    "    dct = Dictionary(corpora)\n",
    "    bow = [dct.doc2bow(line) for line in corpora]\n",
    "    modelTfIdf = TfidfModel(bow, smartirs='ntc')\n",
    "    dic = [(k,v) for k,v in dct.items()]\n",
    "    rev_dct = dict(map(reversed, dic))\n",
    "    \n",
    "    del dct, dic\n",
    "    \n",
    "    print(\"Calculate Weighted Vector for each token of interest-->\")\n",
    "    for i,line in tqdm_notebook(enumerate(corpora), total=len(corpora)):\n",
    "        if len(line)!=0:\n",
    "            embed = []\n",
    "            weights = dict(modelTfIdf[bow[i]])\n",
    "            embed = [fasttext_model[word]*weights[rev_dct[word]] for word in line]\n",
    "#             mean_vec = np.array(embed).mean(axis=0)\n",
    "            result.append(embed)\n",
    "        else:\n",
    "            pass\n",
    "#             mean_vec = np.zeros((model_gensim.vector_size,))\n",
    "\n",
    "#         if not np.mod(len(result), 10000) and len(result)!=0:\n",
    "#             with gzip.open(pathtoexport, 'at') as fz:\n",
    "#             with open(str(pathtoexport),'a', encoding='utf8') as fz: \n",
    "#                 writer = csv.writer(fz, delimiter=';', quotechar='\"', lineterminator='\\n')\n",
    "#                 file_is_empty = os.stat(str(pathtoexport)).st_size == 0\n",
    "#                 if file_is_empty:\n",
    "#                     writer.writerow(['idx','vec'])\n",
    "#                 for k,val in result.items():\n",
    "#                     strarr = ['{0:.8f}'.format(ele) for ele in val]\n",
    "#                     fz.write('{}: '.format(k)+' '.join(strarr)+'\\n')\n",
    "#                     writer.writerow([k,v])\n",
    "\n",
    "#             result = OrderedDict()\n",
    "    \n",
    "    return maxlen, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained BPE Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"models/BPE/sentpbpe.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Weighted Embeddings ( This aproach is suitable only for the case of ad-hoc preparation of X matrix before feeding one on the input of Keras model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnaSegPathTrain = os.path.join(os.getcwd(),'data/dnaseg/csv/DnaSeg4TrainwLabelsSampled_wRandL.csv')\n",
    "pathtoexport    = os.path.join(os.getcwd(),'models/embed/bpe_embeddings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_gensim = joblib.load('./models/fasttext/ft_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxlen, result = weight_words2vec(dnaSegPathTrain, pathtoexport, sp, model_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_seq_pad = sequence.pad_sequences(result, maxlen = maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeding Matrix: Get FT Embeddings without TFIDF weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw2vec = './models/fasttext/ft_300.vec'\n",
    "w2vec = KeyedVectors.load_word2vec_format(fw2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Embed = w2vec.get_keras_embedding(train_embeddings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((sp.GetPieceSize()+1, w2vec.vector_size))\n",
    "for i, vec in enumerate(w2vec.wv.vectors):\n",
    "    embedding_matrix[sp.PieceToId(w2vec.index2word[i])] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnaSegPathTrain = os.path.join(os.getcwd(),'data/dnaseg/csv/DnaSeg4TrainwLabelsSampled_wRandL.csv')\n",
    "data = pd.read_csv(dnaSegPathTrain, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATATGTATTTTCTTTTTGTGGAGAGCATTTTTCCCTCGTGATTACA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TGGAGGGGAAAAGCCAGGAGACCTCCGAGCTTGCACATATTGTAGA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTAACCTTGCAAGAACTCTTCAGGCACATATGGAAGATCTCG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCTGAAGTAAATTATATCATTGAAAGACCAAGCTACCCTCTGAAGA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GACTTGCATACCAACATAATCAGACCGTCTGCAGAAATTCTCCTAC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq  label\n",
       "0     ATATGTATTTTCTTTTTGTGGAGAGCATTTTTCCCTCGTGATTACA      0\n",
       "1     TGGAGGGGAAAAGCCAGGAGACCTCCGAGCTTGCACATATTGTAGA      0\n",
       "2         TTAACCTTGCAAGAACTCTTCAGGCACATATGGAAGATCTCG      0\n",
       "3  TCTGAAGTAAATTATATCATTGAAAGACCAAGCTACCCTCTGAAGA...      0\n",
       "4  GACTTGCATACCAACATAATCAGACCGTCTGCAGAAATTCTCCTAC...      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare 1-st Input: Create one-hot encoded vectors using the `char_indices` map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = data.seq.str.len().max()\n",
    "\n",
    "sentences = data.seq.tolist()\n",
    "next_chars = data.label.tolist()\n",
    "\n",
    "chars = sorted(list(set(sentences[0])))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1865779/1865779 [01:10<00:00, 26525.99it/s]\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)),dtype=np.bool)\n",
    "# y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in tqdm(enumerate(sentences), total=len(sentences)):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "        #y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = to_categorical(next_chars, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2724312, 119, 4), (2724312, 4))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare 2-nd Input: Tensor with Tokens' Id to be passed on Embed Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1865779/1865779 [02:00<00:00, 15425.33it/s]\n",
      "100%|██████████| 1865779/1865779 [00:07<00:00, 243025.38it/s]\n"
     ]
    }
   ],
   "source": [
    "def tokens_to_ids(encoder, x):\n",
    "    x_toks = []\n",
    "    for i in tqdm(range(len(x)), total=len(x)):\n",
    "#         encoder.tokenize(x[i])\n",
    "        x_toks.append(encoder.EncodeAsIds(x[i])[1:])\n",
    "    \n",
    "    max_len = max(map(len, x_toks))\n",
    "    X_arr = np.zeros((len(x_toks), max_len), dtype='int32')\n",
    "    for i, s in tqdm(enumerate(x_toks), total=len(x_toks)):\n",
    "        X_arr[i, 0:len(s)] = s\n",
    "    \n",
    "    return X_arr\n",
    "\n",
    "X_toks = tokens_to_ids(encoder=sp, x=data.seq.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1772490, 45)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_toks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_toks_train, X_toks_test, y_train, y_test = train_test_split(X_toks, y, random_state=42, shuffle=True, test_size=0.05)\n",
    "X_train, X_test, _, _ = train_test_split(X, y, random_state=42, shuffle=True, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_toks, X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train model: Embed+BiLSTM+BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(vocab_size, n_classes, seq_len_emb, seq_len_chars):\n",
    "    \n",
    "    inp = Input(shape =(seq_len_emb,), name='Input1')\n",
    "    emb = Embedding(vocab_size, 300, name='BPE_emb')(inp)\n",
    "    x = Bidirectional(LSTM(units=128, dropout=0.2, recurrent_dropout=0.1, \n",
    "                           return_sequences=False), name='BiLSTM_0')(emb)\n",
    "    \n",
    "#     inp_ = Reshape(target_shape=(seq_len_emb,1), name='Expand_Dims')(inp)\n",
    "#     xlstm = Concatenate(name='Concat_LSTM')([x,inp_])\n",
    "\n",
    "#     x = Bidirectional(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2, \n",
    "#                            return_sequences=False), name='BiLSTM_1')(xlstm)    \n",
    "    \n",
    "    ###\n",
    "    inp2 = Input(shape = (seq_len_chars, n_classes), name='Input2')\n",
    "    y = Conv1D(kernel_size=5,\n",
    "                filters=128,\n",
    "                padding='valid',\n",
    "                activation=\"relu\",\n",
    "                name='Conv1d_0')(inp2)\n",
    "    y = Activation(\"relu\")(y)\n",
    "    y = MaxPool1D(pool_size=5, name='MaxPool1d-1')(y)\n",
    "    y = BatchNormalization(name='BatchNorm-1')(y)\n",
    "        \n",
    "    y = Conv1D(kernel_size=4,\n",
    "                filters=128,\n",
    "                padding='valid',\n",
    "                activation=\"relu\",\n",
    "                name='Conv1d_1')(inp2)\n",
    "    y = Activation(\"tanh\")(y)\n",
    "    y = MaxPool1D(pool_size=4, name='MaxPool1d-1')(y)\n",
    "    y = BatchNormalization(name='BatchNorm-1')(y)    \n",
    "    \n",
    "    y = Conv1D(kernel_size=4,\n",
    "                filters=128,\n",
    "                padding='valid',\n",
    "                activation=\"tanh\",\n",
    "                name='Conv1d_2')(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "    y = MaxPool1D(pool_size=4, name='MaxPool1d-2')(y)\n",
    "    y = BatchNormalization(name='BatchNorm-2')(y)\n",
    "\n",
    "    y = Dropout(0.3, name='Dropout_0.5')(y)\n",
    "    y = Flatten(name='Flatten')(y)\n",
    "    ###\n",
    "    comb = Concatenate(name='Concat')([x,y])\n",
    "\n",
    "    z = Dense(512, activation='relu', name='Dense_1024_0')(comb)\n",
    "#     z = Dropout(0.5, name='Dropout_0.5_0')(z)\n",
    "    z = Dense(512, activation='tanh', name='Dense_1024_1')(z) \n",
    "#     z = Dropout(0.5, name='Dropout_0.5_1')(z)\n",
    "    z = Dense(n_classes, activation='softmax', name='Dense_NCLASS')(z)\n",
    "    model = Model(inputs=[inp, inp2], outputs=z)\n",
    "#     plot_model(model = model, to_file = './img/BiLSTM+emb-CNN.png', show_layer_names=False, show_shapes=True)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input2 (InputLayer)             (None, 120, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1d_1 (Conv1D)               (None, 117, 128)     2176        Input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 117, 128)     0           Conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool1d-1 (MaxPooling1D)      (None, 29, 128)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm-1 (BatchNormalization (None, 29, 128)      512         MaxPool1d-1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv1d_2 (Conv1D)               (None, 26, 128)      65664       BatchNorm-1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 26, 128)      0           Conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool1d-2 (MaxPooling1D)      (None, 6, 128)       0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Input1 (InputLayer)             (None, 45)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm-2 (BatchNormalization (None, 6, 128)       512         MaxPool1d-2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "BPE_emb (Embedding)             (None, 45, 300)      45300       Input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Dropout_0.5 (Dropout)           (None, 6, 128)       0           BatchNorm-2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "BiLSTM_0 (Bidirectional)        (None, 256)          439296      BPE_emb[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Flatten (Flatten)               (None, 768)          0           Dropout_0.5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Concat (Concatenate)            (None, 1024)         0           BiLSTM_0[0][0]                   \n",
      "                                                                 Flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Dense_1024_0 (Dense)            (None, 512)          524800      Concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Dense_1024_1 (Dense)            (None, 512)          262656      Dense_1024_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Dense_NCLASS (Dense)            (None, 4)            2052        Dense_1024_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,342,968\n",
      "Trainable params: 1,342,456\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = embedding_matrix.shape[0] #sp.GetPieceSize()+1 #embedding_matrix.shape[0]\n",
    "MAXSEQLEN = X_toks_train.shape[1]\n",
    "MAXCHARSLEN = X_train.shape[1]\n",
    "\n",
    "model = get_model(vocab_size = VOCAB_SIZE, \n",
    "                  n_classes=len(chars), \n",
    "                  seq_len_emb=MAXSEQLEN, \n",
    "                  seq_len_chars=MAXCHARSLEN)\n",
    "\n",
    "optimizer = SGD(lr=3e-3, momentum=0.1, decay=1e-4)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we wanna use Embedding Matrix with FT vectors then one should uncomment the following lines-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding = model.get_layer('BPE_emb')\n",
    "embedding.set_weights([embedding_matrix])\n",
    "embedding.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Training: Load Model from the last Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './models/keras/bilstm_emb_fasttext.h5'\n",
    "model = load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Conv1d_1_1/kernel:0' shape=(3, 4, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'Conv1d_1_1/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'BatchNorm-1_1/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'BatchNorm-1_1/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'Conv1d_2_1/kernel:0' shape=(3, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'Conv1d_2_1/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'BatchNorm-2_1/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'BatchNorm-2_1/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'BiLSTM_0_1/forward_lstm_9/kernel:0' shape=(300, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'BiLSTM_0_1/forward_lstm_9/recurrent_kernel:0' shape=(128, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'BiLSTM_0_1/forward_lstm_9/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'BiLSTM_0_1/backward_lstm_9/kernel:0' shape=(300, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'BiLSTM_0_1/backward_lstm_9/recurrent_kernel:0' shape=(128, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'BiLSTM_0_1/backward_lstm_9/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Dense_1024_0_1/kernel:0' shape=(1792, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Dense_1024_0_1/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Dense_1024_1_1/kernel:0' shape=(512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Dense_1024_1_1/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Dense_NCLASS_1/kernel:0' shape=(512, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'Dense_NCLASS_1/bias:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'BatchNorm-1_1/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'BatchNorm-1_1/moving_variance:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'BPE_emb_1/embeddings:0' shape=(151, 300) dtype=float32_ref>,\n",
       " <tf.Variable 'BatchNorm-2_1/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'BatchNorm-2_1/moving_variance:0' shape=(128,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1506616 samples, validate on 265874 samples\n",
      "Epoch 1/160\n",
      "1506616/1506616 [==============================] - 1049s 696us/step - loss: 1.3934 - acc: 0.2904 - val_loss: 1.3719 - val_acc: 0.3035\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.37193, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 2/160\n",
      "1506616/1506616 [==============================] - 1052s 698us/step - loss: 1.3739 - acc: 0.3009 - val_loss: 1.3690 - val_acc: 0.3059\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.37193 to 1.36899, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 3/160\n",
      "1506616/1506616 [==============================] - 1052s 698us/step - loss: 1.3712 - acc: 0.3038 - val_loss: 1.3676 - val_acc: 0.3087\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.36899 to 1.36755, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 4/160\n",
      "1506616/1506616 [==============================] - 1074s 713us/step - loss: 1.3696 - acc: 0.3058 - val_loss: 1.3668 - val_acc: 0.3097\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.36755 to 1.36685, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 5/160\n",
      "1506616/1506616 [==============================] - 1032s 685us/step - loss: 1.3690 - acc: 0.3067 - val_loss: 1.3667 - val_acc: 0.3095\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.36685 to 1.36668, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 6/160\n",
      "1506616/1506616 [==============================] - 1032s 685us/step - loss: 1.3685 - acc: 0.3076 - val_loss: 1.3663 - val_acc: 0.3105\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.36668 to 1.36627, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 7/160\n",
      "1506616/1506616 [==============================] - 1041s 691us/step - loss: 1.3681 - acc: 0.3080 - val_loss: 1.3662 - val_acc: 0.3104\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.36627 to 1.36616, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 8/160\n",
      "1506616/1506616 [==============================] - 1032s 685us/step - loss: 1.3677 - acc: 0.3085 - val_loss: 1.3659 - val_acc: 0.3109\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.36616 to 1.36593, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 9/160\n",
      "1506616/1506616 [==============================] - 1034s 687us/step - loss: 1.3674 - acc: 0.3083 - val_loss: 1.3658 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.36593 to 1.36584, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 10/160\n",
      "1506616/1506616 [==============================] - 1036s 688us/step - loss: 1.3671 - acc: 0.3091 - val_loss: 1.3659 - val_acc: 0.3106\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/160\n",
      "1506616/1506616 [==============================] - 1033s 685us/step - loss: 1.3671 - acc: 0.3090 - val_loss: 1.3656 - val_acc: 0.3116\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.36584 to 1.36563, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 12/160\n",
      "1506616/1506616 [==============================] - 1033s 685us/step - loss: 1.3671 - acc: 0.3090 - val_loss: 1.3656 - val_acc: 0.3114\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.36563 to 1.36558, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 13/160\n",
      "1506616/1506616 [==============================] - 1032s 685us/step - loss: 1.3668 - acc: 0.3094 - val_loss: 1.3656 - val_acc: 0.3112\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/160\n",
      "1506616/1506616 [==============================] - 1035s 687us/step - loss: 1.3667 - acc: 0.3097 - val_loss: 1.3654 - val_acc: 0.3112\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.36558 to 1.36543, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 15/160\n",
      "1506616/1506616 [==============================] - 1033s 686us/step - loss: 1.3665 - acc: 0.3097 - val_loss: 1.3654 - val_acc: 0.3116\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.36543 to 1.36541, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 16/160\n",
      "1506616/1506616 [==============================] - 1034s 686us/step - loss: 1.3663 - acc: 0.3098 - val_loss: 1.3654 - val_acc: 0.3120\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.36541 to 1.36536, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 17/160\n",
      "1506616/1506616 [==============================] - 1033s 685us/step - loss: 1.3664 - acc: 0.3102 - val_loss: 1.3653 - val_acc: 0.3117\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.36536 to 1.36529, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 18/160\n",
      "1506616/1506616 [==============================] - 1035s 687us/step - loss: 1.3663 - acc: 0.3103 - val_loss: 1.3653 - val_acc: 0.3116\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/160\n",
      "1506616/1506616 [==============================] - 1032s 685us/step - loss: 1.3663 - acc: 0.3102 - val_loss: 1.3652 - val_acc: 0.3117\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.36529 to 1.36523, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 20/160\n",
      "1506616/1506616 [==============================] - 1035s 687us/step - loss: 1.3663 - acc: 0.3102 - val_loss: 1.3652 - val_acc: 0.3118\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.36523 to 1.36521, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 21/160\n",
      "1506616/1506616 [==============================] - 1033s 686us/step - loss: 1.3659 - acc: 0.3108 - val_loss: 1.3652 - val_acc: 0.3114\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.36521 to 1.36518, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 22/160\n",
      "1506616/1506616 [==============================] - 1034s 686us/step - loss: 1.3661 - acc: 0.3106 - val_loss: 1.3652 - val_acc: 0.3111\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/160\n",
      "1506616/1506616 [==============================] - 1035s 687us/step - loss: 1.3659 - acc: 0.3111 - val_loss: 1.3652 - val_acc: 0.3114\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/160\n",
      "1506616/1506616 [==============================] - 1033s 686us/step - loss: 1.3658 - acc: 0.3109 - val_loss: 1.3651 - val_acc: 0.3118\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.36518 to 1.36507, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 25/160\n",
      "1506616/1506616 [==============================] - 1033s 686us/step - loss: 1.3658 - acc: 0.3109 - val_loss: 1.3651 - val_acc: 0.3116\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.36507 to 1.36506, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 26/160\n",
      "1506616/1506616 [==============================] - 1034s 687us/step - loss: 1.3657 - acc: 0.3109 - val_loss: 1.3651 - val_acc: 0.3119\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/160\n",
      "1506616/1506616 [==============================] - 1035s 687us/step - loss: 1.3657 - acc: 0.3110 - val_loss: 1.3650 - val_acc: 0.3118\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.36506 to 1.36503, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 28/160\n",
      "1506616/1506616 [==============================] - 1036s 688us/step - loss: 1.3657 - acc: 0.3113 - val_loss: 1.3650 - val_acc: 0.3123\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.36503 to 1.36496, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 29/160\n",
      "1506616/1506616 [==============================] - 1035s 687us/step - loss: 1.3656 - acc: 0.3115 - val_loss: 1.3650 - val_acc: 0.3122\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/160\n",
      "1506616/1506616 [==============================] - 1075s 714us/step - loss: 1.3657 - acc: 0.3109 - val_loss: 1.3649 - val_acc: 0.3123\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.36496 to 1.36492, saving model to ./models/keras/bilstm_emb_fasttext.h5\n",
      "Epoch 31/160\n",
      "1506616/1506616 [==============================] - 1035s 687us/step - loss: 1.3655 - acc: 0.3117 - val_loss: 1.3649 - val_acc: 0.3120\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/160\n",
      "1506616/1506616 [==============================] - 1036s 688us/step - loss: 1.3656 - acc: 0.3112 - val_loss: 1.3649 - val_acc: 0.3121\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.000000026077032e-07.\n",
      "Epoch 33/160\n",
      "1506616/1506616 [==============================] - 1036s 687us/step - loss: 1.3655 - acc: 0.3112 - val_loss: 1.3650 - val_acc: 0.3121\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/160\n",
      "1506616/1506616 [==============================] - 1037s 688us/step - loss: 1.3655 - acc: 0.3113 - val_loss: 1.3649 - val_acc: 0.3122\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1506616/1506616 [==============================] - 1033s 686us/step - loss: 1.3654 - acc: 0.3115 - val_loss: 1.3650 - val_acc: 0.3122\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-11.\n",
      "Epoch 36/160\n",
      "1506616/1506616 [==============================] - 1035s 687us/step - loss: 1.3656 - acc: 0.3113 - val_loss: 1.3649 - val_acc: 0.3121\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/160\n",
      " 944384/1506616 [=================>............] - ETA: 6:10 - loss: 1.3654 - acc: 0.3115"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-055c744b6a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m history = model.fit([X_toks_train, X_train], y_train, batch_size=BATCH_SIZE, epochs=n_epoch, shuffle=True,\n\u001b[0;32m---> 11\u001b[0;31m                      validation_split=0.15, verbose=1, callbacks=callbacks).history\n\u001b[0m",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = './models/keras/bilstm_emb_fasttext.h5'\n",
    "\n",
    "callbacks = [EarlyStopping(patience=12, monitor='val_loss'),\n",
    "             ModelCheckpoint(path, monitor='val_loss', verbose=1, save_best_only=True),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=1e-4, patience=3, verbose=1)]\n",
    "\n",
    "BATCH_SIZE=256\n",
    "n_epoch=160\n",
    "\n",
    "history = model.fit([X_toks_train, X_train], y_train, batch_size=BATCH_SIZE, epochs=n_epoch, shuffle=True,\n",
    "                     validation_split=0.15, verbose=1, callbacks=callbacks).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOB Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict([X_toks_test, X_test])\n",
    "y_pred = y_pred.argmax(axis=-1)\n",
    "\n",
    "y_true = y_test.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3 (GPUAI)",
   "language": "python",
   "name": "python36_gpuai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
