{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "curruser = os.environ.get('USER')\n",
    "sys.path.insert(0, './src/')\n",
    "# sys.path.insert(0, '/home/{}/notebooks/support_library/'.format(curruser)) \n",
    "sys.path.insert(0, '/home/{}/python36-libs/lib/python3.6/site-packages/'.format(curruser))\n",
    "from pathlib import Path\n",
    "import re\n",
    "import csv\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "# import utils\n",
    "from LSTMPreProc import preprocIO\n",
    "# from LSTMPostProc import LSTM_pred\n",
    "from Bio import SeqIO\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnaSegPath = ('./data/dnaseg/mart_export.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep = preprocIO()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOStreaming: Fetching data from FASTA format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102020it [00:04, 23548.59it/s]\n"
     ]
    }
   ],
   "source": [
    "seqArr = []\n",
    "for seq in tqdm(prep.streamFastaIO(dnaSegPath)):\n",
    "     seqArr+=[seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(seqArr[0])))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'C': 1, 'G': 2, 'T': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvpath = Path.joinpath(Path(os.getcwd()),'data/dnaseg/csv','DnaSeg4Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finalarr = []\n",
    "# headers = ['seq']\n",
    "# for item in tqdm(seqArr):\n",
    "#     with open(str(csvpath),'a', encoding='utf8') as outcsv: \n",
    "#         writer = csv.writer(outcsv,delimiter=';', quotechar='\"', lineterminator='\\n')\n",
    "#         file_is_empty = os.stat(str(csvpath)).st_size ==0\n",
    "#         if file_is_empty:\n",
    "#             writer.writerow(headers)\n",
    "#         writer.writerow([item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Unidirectional RandomSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(seqArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102020/102020 [20:13<00:00, 84.05it/s]\n"
     ]
    }
   ],
   "source": [
    "finalarr = []\n",
    "headers = ['seq', 'label']\n",
    "csvpath = Path.joinpath(Path(os.getcwd()),'data/dnaseg/csv','DnaSeg4TrainwLabels_wRandL.csv')\n",
    "for item in tqdm(seqArr):\n",
    "    chunks = prep.RandomSamplingGen(item, \n",
    "                                    randsize_center=150,\n",
    "                                    min_left_len=30, max_left_len=60,\n",
    "                                    min_right_len=30, max_right_len=60,)\n",
    "    out = [(chunk[0], char_indices[chunk[1]]) for chunk in chunks]\n",
    "    with open(str(csvpath),'a', encoding='utf8') as outcsv: \n",
    "        writer = csv.writer(outcsv,delimiter=';', quotechar='\"', lineterminator='\\n')\n",
    "        file_is_empty = os.stat(str(csvpath)).st_size ==0\n",
    "        if file_is_empty:\n",
    "            writer.writerow(headers)\n",
    "        for row in out:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvpath = Path.joinpath(Path(os.getcwd()),'data/dnaseg/csv','DnaSeg4TrainwLabels_wRandL.csv')\n",
    "df = pd.read_csv(csvpath, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14267163, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['seq'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14159075, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2831814, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvpath = Path.joinpath(Path(os.getcwd()),'data/dnaseg/csv','DnaSeg4TrainwLabelsSampled_wRandL.csv')\n",
    "df_frac = df.groupby('label', group_keys=False).apply(lambda x: x.sample(n=int(np.rint(0.2*len(x))), random_state=42, axis=0))\n",
    "df_frac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_frac.to_csv(csvpath,index=False, encoding='utf8',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indx = np.array(df_frac.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oobdf = df[~df.index.isin(indx)]\n",
    "oobdf_frac = oobdf.groupby('label', group_keys=False).apply(lambda x: x.sample(n=int(np.rint(0.1*len(x))), random_state=42, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvpath = Path.joinpath(Path(os.getcwd()),'data/dnaseg/csv','DnaSeg4ValwLabelsSampled_wRandL.csv')\n",
    "oobdf_frac.to_csv(csvpath,index=False, encoding='utf8',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csvpath = Path.joinpath(Path(os.getcwd()),'data/dnaseg/csv','DnaSeg4TrainwLabelsSampled_wRandL.csv')\n",
    "# df = pd.read_csv(csvpath, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert sentences to bag-of-CharTriGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_trigrams():\n",
    "  \"\"\"\n",
    "      Generates all trigrams for characters from `trigram_chars`\n",
    "  \"\"\"\n",
    "  trigram_chars=\"ACGT\"\n",
    "  t3=[''.join(x) for x in itertools.product(trigram_chars,repeat=3)] #len(words)>=3\n",
    "  t2_start=['#'+''.join(x) for x in itertools.product(trigram_chars,repeat=2)] #len(words)==2\n",
    "  t2_end=[''.join(x)+'#' for x in itertools.product(trigram_chars,repeat=2)] #len(words)==2\n",
    "  t1=['#'+''.join(x)+'#' for x in itertools.product(trigram_chars)] #len(words)==1\n",
    "  trigrams=t3+t2_start+t2_end+t1\n",
    "  vocab_size=len(trigrams)\n",
    "  trigram_map=dict(zip(trigrams,range(1,vocab_size+1))) # trigram to index mapping, indices starting from 1\n",
    "  return trigram_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences_to_bag_of_trigrams(sentences):\n",
    "    \"\"\"\n",
    "      Converts a sentence to bag-of-trigrams\n",
    "      `sentences`: list of strings\n",
    "      `trigram_BOW`: return value, (len(sentences),len(trigram_map)) size array\n",
    "    \"\"\"\n",
    "    trigram_map=gen_trigrams()\n",
    "    trigram_BOW=np.zeros((len(sentences),len(trigram_map))) # one row for each sentence\n",
    "    filter_pat=r'[\\!\"#&\\(\\)\\*\\+,-\\./:;<=>\\?\\[\\\\\\]\\^_`\\{\\|\\}~\\t\\n]' # characters to filter out from the input\n",
    "    for j,sent in enumerate(sentences):\n",
    "      sent=re.sub(fiter_pat, '', sent).lower() # filter out special characters from input\n",
    "      sent=re.sub(r\"(\\s)\\s+\", r\"\\1\", sent) # reduce multiple whitespaces to single whitespace\n",
    "      words=sent.split(' ')\n",
    "      indices=collections.defaultdict(int)\n",
    "      for word in words:\n",
    "          word='#'+word+'#'\n",
    "          #print(word)\n",
    "          for k in range(len(word)-2): # generate all trigrams for word `word` and update `indices`\n",
    "              trig=word[k:k+3]\n",
    "              idx=trigram_map.get(trig, 0)\n",
    "              #print(trig,idx)\n",
    "              indices[idx]=indices[idx]+1     \n",
    "      for key,val in indices.items(): #covert `indices` dict to np array\n",
    "          trigram_BOW[j,key]=val\n",
    "    return trigram_BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_map=gen_trigrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAA': 1,\n",
       " 'AAC': 2,\n",
       " 'AAG': 3,\n",
       " 'AAT': 4,\n",
       " 'ACA': 5,\n",
       " 'ACC': 6,\n",
       " 'ACG': 7,\n",
       " 'ACT': 8,\n",
       " 'AGA': 9,\n",
       " 'AGC': 10,\n",
       " 'AGG': 11,\n",
       " 'AGT': 12,\n",
       " 'ATA': 13,\n",
       " 'ATC': 14,\n",
       " 'ATG': 15,\n",
       " 'ATT': 16,\n",
       " 'CAA': 17,\n",
       " 'CAC': 18,\n",
       " 'CAG': 19,\n",
       " 'CAT': 20,\n",
       " 'CCA': 21,\n",
       " 'CCC': 22,\n",
       " 'CCG': 23,\n",
       " 'CCT': 24,\n",
       " 'CGA': 25,\n",
       " 'CGC': 26,\n",
       " 'CGG': 27,\n",
       " 'CGT': 28,\n",
       " 'CTA': 29,\n",
       " 'CTC': 30,\n",
       " 'CTG': 31,\n",
       " 'CTT': 32,\n",
       " 'GAA': 33,\n",
       " 'GAC': 34,\n",
       " 'GAG': 35,\n",
       " 'GAT': 36,\n",
       " 'GCA': 37,\n",
       " 'GCC': 38,\n",
       " 'GCG': 39,\n",
       " 'GCT': 40,\n",
       " 'GGA': 41,\n",
       " 'GGC': 42,\n",
       " 'GGG': 43,\n",
       " 'GGT': 44,\n",
       " 'GTA': 45,\n",
       " 'GTC': 46,\n",
       " 'GTG': 47,\n",
       " 'GTT': 48,\n",
       " 'TAA': 49,\n",
       " 'TAC': 50,\n",
       " 'TAG': 51,\n",
       " 'TAT': 52,\n",
       " 'TCA': 53,\n",
       " 'TCC': 54,\n",
       " 'TCG': 55,\n",
       " 'TCT': 56,\n",
       " 'TGA': 57,\n",
       " 'TGC': 58,\n",
       " 'TGG': 59,\n",
       " 'TGT': 60,\n",
       " 'TTA': 61,\n",
       " 'TTC': 62,\n",
       " 'TTG': 63,\n",
       " 'TTT': 64,\n",
       " '#AA': 65,\n",
       " '#AC': 66,\n",
       " '#AG': 67,\n",
       " '#AT': 68,\n",
       " '#CA': 69,\n",
       " '#CC': 70,\n",
       " '#CG': 71,\n",
       " '#CT': 72,\n",
       " '#GA': 73,\n",
       " '#GC': 74,\n",
       " '#GG': 75,\n",
       " '#GT': 76,\n",
       " '#TA': 77,\n",
       " '#TC': 78,\n",
       " '#TG': 79,\n",
       " '#TT': 80,\n",
       " 'AA#': 81,\n",
       " 'AC#': 82,\n",
       " 'AG#': 83,\n",
       " 'AT#': 84,\n",
       " 'CA#': 85,\n",
       " 'CC#': 86,\n",
       " 'CG#': 87,\n",
       " 'CT#': 88,\n",
       " 'GA#': 89,\n",
       " 'GC#': 90,\n",
       " 'GG#': 91,\n",
       " 'GT#': 92,\n",
       " 'TA#': 93,\n",
       " 'TC#': 94,\n",
       " 'TG#': 95,\n",
       " 'TT#': 96,\n",
       " '#A#': 97,\n",
       " '#C#': 98,\n",
       " '#G#': 99,\n",
       " '#T#': 100}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trigram_BOW = sentences_to_bag_of_trigrams(seqArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut the corpus into BiDirectional chunks of 30 characters (shift by the left and right from the next character to predict), spacing the sequences by 5 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 30\n",
    "step = 5\n",
    "sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102020/102020 [00:11<00:00, 8720.30it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences, next_chars = prep.genSeqMoveRightChar(seqArr, SEQUENCE_LENGTH, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102020/102020 [00:11<00:00, 8570.95it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences, next_chars_indx = prep.genSeqMoveRight(seqArr, SEQUENCE_LENGTH, step, char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'seq':sentences,'label':next_chars_indx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'seq':sentences,'label':next_chars})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling some fraction from generated sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_frac = df.groupby('label', group_keys=False).apply(lambda x: x.sample(n=int(np.rint(0.4*len(x))), random_state=42, axis=0))\n",
    "# df_frac.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G    2451616\n",
       "A    2436500\n",
       "C    2422670\n",
       "T    2045139\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_frac.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe for Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvpath = Path.joinpath(Path(os.getcwd()),'data/dnaseg/csv','DnaSeg4TrainCharLabel.csv')\n",
    "df_frac.to_csv(csvpath,index=False, encoding='utf8',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csvpath = Path.joinpath(Path(os.getcwd()),'data/dnaseg/csv','DnaSeg4TrainwLabels.csv')\n",
    "df_frac.to_csv(csvpath,index=False, encoding='utf8',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe for OOB validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indx = np.array(df_frac.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oobdf = df[~df.index.isin(indx)]\n",
    "oobdf_frac = oobdf.groupby('label', group_keys=False).apply(lambda x: x.sample(n=int(np.rint(0.1*len(x))), random_state=42, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    367742\n",
       "0    365475\n",
       "1    363400\n",
       "3    306771\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oobdf_frac.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvpath = Path.joinpath(Path(os.getcwd()),'data/dnaseg/csv','DnaSeg4ValCharLabel.csv')\n",
    "oobdf_frac.to_csv(csvpath,index=False, encoding='utf8',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csvpath = Path.joinpath(Path(os.getcwd()),'data/dnaseg/csv','DnaSeg4ValwLabels.csv')\n",
    "# oobdf_frac.to_csv(csvpath,index=False, encoding='utf8',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Bidirectional chunked sequences and transform omitted char into its label encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenc = LabelEncoder()\n",
    "lenc.fit_transform(np.array(['A','T','C','G']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finalarr = []\n",
    "headers = ['seq']\n",
    "for item in tqdm(seqArr):\n",
    "    \n",
    "    chunkesRight = prep.getChunkesFromSeqToRight(item, lenc = lenc)\n",
    "    chunkesLeft  = prep.getChunkesFromSeqToLeft(item,  lenc = lenc)\n",
    "    res = chunkesRight+chunkesLeft\n",
    "    finalarr+=res\n",
    "\n",
    "    with open(str(csvpath),'a', encoding='utf8') as outcsv: \n",
    "        writer = csv.writer(outcsv,delimiter=';', quotechar='\"', lineterminator='\\n')\n",
    "        file_is_empty = os.stat(str(csvpath)).st_size ==0\n",
    "        if file_is_empty:\n",
    "            writer.writerow(headers)\n",
    "        for item in finalarr:\n",
    "            writer.writerow(item)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3 (GPUAI)",
   "language": "python",
   "name": "python36_gpuai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
