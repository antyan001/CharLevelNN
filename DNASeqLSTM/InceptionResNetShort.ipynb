{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.functional\")\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Initialization amd Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Activation, Permute\n",
    "from keras.layers import LSTM, Dropout, CuDNNGRU, Bidirectional\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from keras.optimizers import RMSprop, Adam, Adagrad, Adadelta, SGD\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Convolution1D, Conv1D, Conv2D, \\\n",
    "                         MaxPool1D, MaxPool2D, Lambda, GlobalMaxPooling1D, \\\n",
    "                         GlobalAveragePooling1D, GlobalAveragePooling2D, \\\n",
    "                         BatchNormalization, Activation, AveragePooling1D, \\\n",
    "                         Concatenate, concatenate, Reshape, Embedding\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, \\\n",
    "                                    KFold, StratifiedKFold, RepeatedKFold, RepeatedStratifiedKFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with K.tf.device('/GPU:0'):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1.\n",
    "    session = tf.Session(config=config)\n",
    "    K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "curruser = os.environ.get('USER')\n",
    "sys.path.insert(0, './src/')\n",
    "\n",
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import csv\n",
    "\n",
    "from LSTMPreProc import preprocIO\n",
    "from Bio import SeqIO\n",
    "import smart_open\n",
    "# from bpe import Encoder\n",
    "import sentencepiece as spm\n",
    "# from tokenizers import CharBPETokenizer, ByteLevelBPETokenizer, SentencePieceBPETokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pylab import rcParams\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 12, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel, KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.utils import tokenize\n",
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dnaSegPath = ('./data/dnaseg/mart_export.txt')\n",
    "# prep = preprocIO()\n",
    "# seqArr = []\n",
    "# for seq in tqdm_notebook(prep.streamFastaIO(dnaSegPath)):\n",
    "#      seqArr+=[seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    plt.plot(history['acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    \n",
    "def confusion_matrix_heatmap(y_true, y_pred):\n",
    "    '''\n",
    "    Построение Confusion matrix (матрицы ошибок)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test: pandas.Series, numpy.array\n",
    "        Целевая для обучающего набора\n",
    "    y_pred: pandas.Series, numpy.array\n",
    "        Значения целевой переменной, предсказанные классификатором\n",
    "    '''\n",
    "    rcParams['figure.figsize'] = 6, 4\n",
    "    sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d', cmap='Greens')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained BPE Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"models/BPE/sentpbpe.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embedding Matrix: `(Token's Id, Weighted Vector)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import OrderedDict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_words2vec(pathtofile, pathtoexport, sp, fasttext_model):\n",
    "    corpora = []\n",
    "    result = []  \n",
    "    print('Tokenize sequense corpora from file-->')\n",
    "    path = datapath(pathtofile)  # absolute path to corpus\n",
    "    with open(path, 'r', encoding='utf8', errors = 'ignore') as fin:\n",
    "        for line in tqdm_notebook(fin):\n",
    "            line = line.rstrip('\\n')\n",
    "            corpora.append(list(sp.EncodeAsPieces(line))[1:])\n",
    "    \n",
    "    maxlen = max(map(len, corpora))\n",
    "    \n",
    "    print(\"max tokens len: {}\".format(maxlen))\n",
    "    \n",
    "    print(\"Build BOW and calculate TFIDF...\")\n",
    "    dct = Dictionary(corpora)\n",
    "    bow = [dct.doc2bow(line) for line in corpora]\n",
    "    modelTfIdf = TfidfModel(bow, smartirs='ntc')\n",
    "    dic = [(k,v) for k,v in dct.items()]\n",
    "    rev_dct = dict(map(reversed, dic))\n",
    "    \n",
    "    del dct, dic\n",
    "    \n",
    "    print(\"Calculate Weighted Vector for each token of interest-->\")\n",
    "    for i,line in tqdm_notebook(enumerate(corpora), total=len(corpora)):\n",
    "        if len(line)!=0:\n",
    "            embed = []\n",
    "            weights = dict(modelTfIdf[bow[i]])\n",
    "            embed = [fasttext_model[word]*weights[rev_dct[word]] for word in line]\n",
    "#             mean_vec = np.array(embed).mean(axis=0)\n",
    "            result.append(embed)\n",
    "        else:\n",
    "            pass\n",
    "#             mean_vec = np.zeros((model_gensim.vector_size,))\n",
    "\n",
    "#         if not np.mod(len(result), 10000) and len(result)!=0:\n",
    "#             with gzip.open(pathtoexport, 'at') as fz:\n",
    "#             with open(str(pathtoexport),'a', encoding='utf8') as fz: \n",
    "#                 writer = csv.writer(fz, delimiter=';', quotechar='\"', lineterminator='\\n')\n",
    "#                 file_is_empty = os.stat(str(pathtoexport)).st_size == 0\n",
    "#                 if file_is_empty:\n",
    "#                     writer.writerow(['idx','vec'])\n",
    "#                 for k,val in result.items():\n",
    "#                     strarr = ['{0:.8f}'.format(ele) for ele in val]\n",
    "#                     fz.write('{}: '.format(k)+' '.join(strarr)+'\\n')\n",
    "#                     writer.writerow([k,v])\n",
    "\n",
    "#             result = OrderedDict()\n",
    "    \n",
    "    return maxlen, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Weighted Embeddings ( This aproach is suitable only for the case of ad-hoc preparation of X matrix before feeding one on the input of Keras model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnaSegPathTrain = os.path.join(os.getcwd(),'data/dnaseg/csv/DnaSeg4TrainwLabelsSampled_wRandL.csv')\n",
    "pathtoexport    = os.path.join(os.getcwd(),'models/embed/bpe_embeddings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_gensim = joblib.load('./models/fasttext/ft_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxlen, result = weight_words2vec(dnaSegPathTrain, pathtoexport, sp, model_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_seq_pad = sequence.pad_sequences(result, maxlen = maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeding Matrix: Get FT Embeddings without TFIDF weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw2vec = './models/fasttext/ft_300.vec'\n",
    "w2vec = KeyedVectors.load_word2vec_format(fw2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embed = w2vec.get_keras_embedding(train_embeddings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((sp.GetPieceSize()+1, w2vec.vector_size))\n",
    "for i, vec in enumerate(w2vec.wv.vectors):\n",
    "    embedding_matrix[sp.PieceToId(w2vec.index2word[i])] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnaSegPathTrain = os.path.join(os.getcwd(),'data/dnaseg/csv/DnaSeg4TrainwLabelsSampled_wRandL.csv')\n",
    "data = pd.read_csv(dnaSegPathTrain, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GGACTGTGTGTGCAAAGGCGGAGAGGCAGCTGAGGCAGAAGCAGGA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TGGAGCTGTCTCGCCTGGCCCGGATTGCGGACACCAAGATGAAATC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACCAAAAGATATTGGATTCCGACTCGACTCATTACATCCATCCTGC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATCTTCGTGGATGATGAGACGAAGTTGACGCTGCATGGGTTGCAGC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATACTGTCTTGCCATTTCCCTGCCTCTTTGACACTTATGTAGAAGT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq  label\n",
       "0  GGACTGTGTGTGCAAAGGCGGAGAGGCAGCTGAGGCAGAAGCAGGA...      0\n",
       "1  TGGAGCTGTCTCGCCTGGCCCGGATTGCGGACACCAAGATGAAATC...      0\n",
       "2  ACCAAAAGATATTGGATTCCGACTCGACTCATTACATCCATCCTGC...      0\n",
       "3  ATCTTCGTGGATGATGAGACGAAGTTGACGCTGCATGGGTTGCAGC...      0\n",
       "4  ATACTGTCTTGCCATTTCCCTGCCTCTTTGACACTTATGTAGAAGT...      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare 1-st Input: Create one-hot encoded vectors using the `char_indices` map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = data.seq.str.len().max()\n",
    "\n",
    "sentences = data.seq.tolist()\n",
    "next_chars = data.label.tolist()\n",
    "\n",
    "chars = sorted(list(set(sentences[0])))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)),dtype=np.bool)\n",
    "# y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in tqdm_notebook(enumerate(sentences), total=len(sentences)):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "        #y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = to_categorical(next_chars, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare 2-nd Input: Tensor with Tokens' Id to be passed on Embed Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7072636797be423ebff08fe6f6059a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2831814.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea89dfd4b93482dad7ed56a6d497026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2831814.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokens_to_ids(encoder, x):\n",
    "    x_toks = []\n",
    "    for i in tqdm_notebook(range(len(x)), total=len(x)):\n",
    "#         encoder.tokenize(x[i])\n",
    "        x_toks.append(encoder.EncodeAsIds(x[i])[1:])\n",
    "    \n",
    "    max_len = max(map(len, x_toks))\n",
    "    X_arr = np.zeros((len(x_toks), max_len), dtype='int32')\n",
    "    for i, s in tqdm_notebook(enumerate(x_toks), total=len(x_toks)):\n",
    "        X_arr[i, 0:len(s)] = s\n",
    "    \n",
    "    return X_arr\n",
    "\n",
    "X_toks = tokens_to_ids(encoder=sp, x=data.seq.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_toks = X_toks[:,:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_toks_train, X_toks_test, y_train, y_test = train_test_split(X_toks, y, random_state=42, shuffle=True, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_toks_train, X_toks_test, y_train, y_test = train_test_split(X_toks, y, random_state=42, shuffle=True, test_size=0.05)\n",
    "# X_train, X_test, _, _ = train_test_split(X, y, random_state=42, shuffle=True, test_size=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del X_toks, X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Inception-ResNet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x,numfilt,filtsz,strides=1,pad='same',act=True,name=None):\n",
    "    x = Conv2D(numfilt,filtsz,strides=strides,padding=pad,\n",
    "               data_format='channels_last',use_bias=False,name=name+'conv2d')(x)\n",
    "    x = BatchNormalization(axis=3,scale=False,name=name+'conv2d'+'bn')(x)\n",
    "    if act:\n",
    "        x = Activation('relu',name=name+'conv2d'+'act')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception ResNet A block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def incresA(x,scale,name=None):\n",
    "    pad = 'same'\n",
    "    branch0 = conv2d(x,8,1,1,pad,True,name=name+'b0')\n",
    "    branch1 = conv2d(x,8,1,1,pad,True,name=name+'b1_1')\n",
    "    branch1 = conv2d(branch1,32,3,1,pad,True,name=name+'b1_2')\n",
    "    branch2 = conv2d(x,8,1,1,pad,True,name=name+'b2_1')\n",
    "    branch2 = conv2d(branch2,12,3,1,pad,True,name=name+'b2_2')\n",
    "    branch2 = conv2d(branch2,16,3,1,pad,True,name=name+'b2_3')\n",
    "    branches = [branch0,branch1,branch2]\n",
    "    mixed = Concatenate(axis=3, name=name + '_concat')(branches)\n",
    "    filt_exp_1x1 = conv2d(mixed,96,1,1,pad,False,name=name+'filt_exp_1x1')\n",
    "    final_lay = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
    "                       output_shape=K.int_shape(x)[1:],\n",
    "                       arguments={'scale': scale},\n",
    "                       name=name+'act_scaling')([x, filt_exp_1x1])\n",
    "    return final_lay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception ResNet B block#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def incresB(x,scale,name=None):\n",
    "    pad = 'same'\n",
    "    branch0 = conv2d(x,48,1,1,pad,True,name=name+'b0')\n",
    "    branch1 = conv2d(x,32,1,1,pad,True,name=name+'b1_1')\n",
    "    branch1 = conv2d(branch1,40,[1,7],1,pad,True,name=name+'b1_2')\n",
    "    branch1 = conv2d(branch1,48,[7,1],1,pad,True,name=name+'b1_3')\n",
    "    branches = [branch0,branch1]\n",
    "    mixed = Concatenate(axis=3, name=name + '_mixed')(branches)\n",
    "    filt_exp_1x1 = conv2d(mixed,288,1,1,pad,False,name=name+'filt_exp_1x1')\n",
    "    final_lay = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
    "                      output_shape=K.int_shape(x)[1:],\n",
    "                      arguments={'scale': scale},\n",
    "                      name=name+'act_scaling')([x, filt_exp_1x1])\n",
    "    return final_lay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception ResNet C block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def incresC(x,scale,name=None):\n",
    "    pad = 'same'\n",
    "    branch0 = conv2d(x,48,1,1,pad,True,name=name+'b0')\n",
    "    branch1 = conv2d(x,48,1,1,pad,True,name=name+'b1_1')\n",
    "    branch1 = conv2d(branch1,56,[1,3],1,pad,True,name=name+'b1_2')\n",
    "    branch1 = conv2d(branch1,64,[3,1],1,pad,True,name=name+'b1_3')\n",
    "    branches = [branch0,branch1]\n",
    "    mixed = Concatenate(axis=3, name=name + '_mixed')(branches)\n",
    "    filt_exp_1x1 = conv2d(mixed,512,1,1,pad,False,name=name+'fin1x1')\n",
    "    final_lay = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
    "                      output_shape=K.int_shape(x)[1:],\n",
    "                      arguments={'scale': scale},\n",
    "                      name=name+'act_saling')([x, filt_exp_1x1])\n",
    "    return final_lay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(vocab_size, emb_vec_size, repeat, n_classes, seq_len_emb, seq_len_chars=None):\n",
    "\n",
    "    ip  = Input(shape =(seq_len_emb,), name='Input1')\n",
    "    emb = Embedding(vocab_size, emb_vec_size, name='BPE_emb')(ip)\n",
    "    rep = Lambda(lambda inputs: K.repeat_elements(inputs,rep=repeat,axis=2),\n",
    "                 name=\"repeat_elems\")(emb)\n",
    "    pre = Reshape((K.int_shape(rep)[1],emb_vec_size,repeat))(rep)      \n",
    "\n",
    "    # Stem block\n",
    "\n",
    "    x = conv2d(pre,8,2,2,'valid',True,name='conv1')\n",
    "    x = conv2d(x,8,2,1,'valid',True,name='conv2')\n",
    "    x = conv2d(x,16,2,1,'valid',True,name='conv3')\n",
    "\n",
    "    x_11 = MaxPool2D(2,strides=1,padding='valid',name='stem_br_11'+'_maxpool_1')(x)\n",
    "    x_12 = conv2d(x,16,2,1,'valid',True,name='stem_br_12')\n",
    "\n",
    "    x = Concatenate(axis=3, name = 'stem_concat_1')([x_11,x_12])\n",
    "\n",
    "    x_21 = conv2d(x,16,1,1,'same',True,name='stem_br_211')\n",
    "    x_21 = conv2d(x_21,16,[1,7],1,'same',True,name='stem_br_212')\n",
    "    x_21 = conv2d(x_21,16,[7,1],1,'same',True,name='stem_br_213')\n",
    "    x_21 = conv2d(x_21,24,2,1,'valid',True,name='stem_br_214')\n",
    "\n",
    "    x_22 = conv2d(x,16,1,1,'same',True,name='stem_br_221')\n",
    "    x_22 = conv2d(x_22,24,2,1,'valid',True,name='stem_br_222')\n",
    "\n",
    "    x = Concatenate(axis=3, name = 'stem_concat_2')([x_21,x_22])\n",
    "\n",
    "    x_31 = conv2d(x,48,2,1,'valid',True,name='stem_br_31')\n",
    "    x_32 = MaxPool2D(2,strides=1,padding='valid',name='stem_br_32'+'_maxpool_2')(x)\n",
    "    x = Concatenate(axis=3, name = 'stem_concat_3')([x_31,x_32])    \n",
    "\n",
    "    #Inception-ResNet-A modules\n",
    "    x = incresA(x,0.15,name='incresA_1')\n",
    "    x = incresA(x,0.15,name='incresA_2')\n",
    "    x = incresA(x,0.15,name='incresA_3')\n",
    "\n",
    "    #35 × 35 to 17 × 17 reduction module.\n",
    "    x_red_11 = MaxPool2D(3,strides=2,padding='valid',name='red_maxpool_1')(x)\n",
    "    x_red_12 = conv2d(x,96,3,2,'valid',True,name='x_red1_c1')\n",
    "\n",
    "    x_red_13 = conv2d(x,64,1,1,'same',True,name='x_red1_c2_1')\n",
    "    x_red_13 = conv2d(x_red_13,64,3,1,'same',True,name='x_red1_c2_2')\n",
    "    x_red_13 = conv2d(x_red_13,96,3,2,'valid',True,name='x_red1_c2_3')\n",
    "\n",
    "    x = Concatenate(axis=3, name='red_concat_1')([x_red_11,x_red_12,x_red_13])\n",
    "\n",
    "    #Inception-ResNet-B modules\n",
    "    x = incresB(x,0.1,name='incresB_1')\n",
    "    x = incresB(x,0.1,name='incresB_2')\n",
    "    x = incresB(x,0.1,name='incresB_3')\n",
    "#     x = incresB(x,0.1,name='incresB_4')\n",
    "#     x = incresB(x,0.1,name='incresB_5')\n",
    "\n",
    "    #17 × 17 to 8 × 8 reduction module.\n",
    "    x_red_21 = MaxPool2D(3,strides=2,padding='valid',name='red_maxpool_2')(x)\n",
    "\n",
    "    x_red_22 = conv2d(x,64,1,1,'same',True,name='x_red2_c11')\n",
    "    x_red_22 = conv2d(x_red_22,96,3,2,'valid',True,name='x_red2_c12')\n",
    "\n",
    "    x_red_23 = conv2d(x,64,1,1,'same',True,name='x_red2_c21')\n",
    "    x_red_23 = conv2d(x_red_23,64,3,2,'valid',True,name='x_red2_c22')\n",
    "\n",
    "    x_red_24 = conv2d(x,64,1,1,'same',True,name='x_red2_c31')\n",
    "    x_red_24 = conv2d(x_red_24,64,3,1,'same',True,name='x_red2_c32')\n",
    "    x_red_24 = conv2d(x_red_24,64,3,2,'valid',True,name='x_red2_c33')\n",
    "\n",
    "    x = Concatenate(axis=3, name='red_concat_2')([x_red_21,x_red_22,x_red_23,x_red_24])\n",
    "\n",
    "    #Inception-ResNet-C modules\n",
    "    x = incresC(x,0.2,name='incresC_1')\n",
    "    x = incresC(x,0.2,name='incresC_2')\n",
    "    x = incresC(x,0.2,name='incresC_3')\n",
    "    #TOP\n",
    "    x = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    z = Dense(n_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(ip,z)\n",
    "#     plot_model(model = model, to_file = './img/InceptionResNet.png', show_layer_names=False, show_shapes=True)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input1 (InputLayer)             (None, 45)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "BPE_emb (Embedding)             (None, 45, 300)      45300       Input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "repeat_elems (Lambda)           (None, 45, 1500)     0           BPE_emb[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 45, 300, 5)   0           repeat_elems[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1conv2d (Conv2D)            (None, 22, 150, 8)   160         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1conv2dbn (BatchNormalizati (None, 22, 150, 8)   24          conv1conv2d[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1conv2dact (Activation)     (None, 22, 150, 8)   0           conv1conv2dbn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2conv2d (Conv2D)            (None, 21, 149, 8)   256         conv1conv2dact[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2conv2dbn (BatchNormalizati (None, 21, 149, 8)   24          conv2conv2d[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2conv2dact (Activation)     (None, 21, 149, 8)   0           conv2conv2dbn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3conv2d (Conv2D)            (None, 20, 148, 16)  512         conv2conv2dact[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3conv2dbn (BatchNormalizati (None, 20, 148, 16)  48          conv3conv2d[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3conv2dact (Activation)     (None, 20, 148, 16)  0           conv3conv2dbn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_12conv2d (Conv2D)       (None, 19, 147, 16)  1024        conv3conv2dact[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_12conv2dbn (BatchNormal (None, 19, 147, 16)  48          stem_br_12conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_11_maxpool_1 (MaxPoolin (None, 19, 147, 16)  0           conv3conv2dact[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_12conv2dact (Activation (None, 19, 147, 16)  0           stem_br_12conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stem_concat_1 (Concatenate)     (None, 19, 147, 32)  0           stem_br_11_maxpool_1[0][0]       \n",
      "                                                                 stem_br_12conv2dact[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_211conv2d (Conv2D)      (None, 19, 147, 16)  512         stem_concat_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_211conv2dbn (BatchNorma (None, 19, 147, 16)  48          stem_br_211conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_211conv2dact (Activatio (None, 19, 147, 16)  0           stem_br_211conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_212conv2d (Conv2D)      (None, 19, 147, 16)  1792        stem_br_211conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_212conv2dbn (BatchNorma (None, 19, 147, 16)  48          stem_br_212conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_212conv2dact (Activatio (None, 19, 147, 16)  0           stem_br_212conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_213conv2d (Conv2D)      (None, 19, 147, 16)  1792        stem_br_212conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_221conv2d (Conv2D)      (None, 19, 147, 16)  512         stem_concat_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_213conv2dbn (BatchNorma (None, 19, 147, 16)  48          stem_br_213conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_221conv2dbn (BatchNorma (None, 19, 147, 16)  48          stem_br_221conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_213conv2dact (Activatio (None, 19, 147, 16)  0           stem_br_213conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_221conv2dact (Activatio (None, 19, 147, 16)  0           stem_br_221conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_214conv2d (Conv2D)      (None, 18, 146, 24)  1536        stem_br_213conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_222conv2d (Conv2D)      (None, 18, 146, 24)  1536        stem_br_221conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_214conv2dbn (BatchNorma (None, 18, 146, 24)  72          stem_br_214conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_222conv2dbn (BatchNorma (None, 18, 146, 24)  72          stem_br_222conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_214conv2dact (Activatio (None, 18, 146, 24)  0           stem_br_214conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_222conv2dact (Activatio (None, 18, 146, 24)  0           stem_br_222conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stem_concat_2 (Concatenate)     (None, 18, 146, 48)  0           stem_br_214conv2dact[0][0]       \n",
      "                                                                 stem_br_222conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_31conv2d (Conv2D)       (None, 17, 145, 48)  9216        stem_concat_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_31conv2dbn (BatchNormal (None, 17, 145, 48)  144         stem_br_31conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_31conv2dact (Activation (None, 17, 145, 48)  0           stem_br_31conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stem_br_32_maxpool_2 (MaxPoolin (None, 17, 145, 48)  0           stem_concat_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_concat_3 (Concatenate)     (None, 17, 145, 96)  0           stem_br_31conv2dact[0][0]        \n",
      "                                                                 stem_br_32_maxpool_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_1conv2d (Conv2D)    (None, 17, 145, 8)   768         stem_concat_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_1conv2dbn (BatchNor (None, 17, 145, 8)   24          incresA_1b2_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_1conv2dact (Activat (None, 17, 145, 8)   0           incresA_1b2_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b1_1conv2d (Conv2D)    (None, 17, 145, 8)   768         stem_concat_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_2conv2d (Conv2D)    (None, 17, 145, 12)  864         incresA_1b2_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b1_1conv2dbn (BatchNor (None, 17, 145, 8)   24          incresA_1b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_2conv2dbn (BatchNor (None, 17, 145, 12)  36          incresA_1b2_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b1_1conv2dact (Activat (None, 17, 145, 8)   0           incresA_1b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_2conv2dact (Activat (None, 17, 145, 12)  0           incresA_1b2_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b0conv2d (Conv2D)      (None, 17, 145, 8)   768         stem_concat_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b1_2conv2d (Conv2D)    (None, 17, 145, 32)  2304        incresA_1b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_3conv2d (Conv2D)    (None, 17, 145, 16)  1728        incresA_1b2_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b0conv2dbn (BatchNorma (None, 17, 145, 8)   24          incresA_1b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b1_2conv2dbn (BatchNor (None, 17, 145, 32)  96          incresA_1b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_3conv2dbn (BatchNor (None, 17, 145, 16)  48          incresA_1b2_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b0conv2dact (Activatio (None, 17, 145, 8)   0           incresA_1b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b1_2conv2dact (Activat (None, 17, 145, 32)  0           incresA_1b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1b2_3conv2dact (Activat (None, 17, 145, 16)  0           incresA_1b2_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1_concat (Concatenate)  (None, 17, 145, 56)  0           incresA_1b0conv2dact[0][0]       \n",
      "                                                                 incresA_1b1_2conv2dact[0][0]     \n",
      "                                                                 incresA_1b2_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1filt_exp_1x1conv2d (Co (None, 17, 145, 96)  5376        incresA_1_concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "incresA_1filt_exp_1x1conv2dbn ( (None, 17, 145, 96)  288         incresA_1filt_exp_1x1conv2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "incresA_1act_scaling (Lambda)   (None, 17, 145, 96)  0           stem_concat_3[0][0]              \n",
      "                                                                 incresA_1filt_exp_1x1conv2dbn[0][\n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_1conv2d (Conv2D)    (None, 17, 145, 8)   768         incresA_1act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_1conv2dbn (BatchNor (None, 17, 145, 8)   24          incresA_2b2_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_1conv2dact (Activat (None, 17, 145, 8)   0           incresA_2b2_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b1_1conv2d (Conv2D)    (None, 17, 145, 8)   768         incresA_1act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_2conv2d (Conv2D)    (None, 17, 145, 12)  864         incresA_2b2_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b1_1conv2dbn (BatchNor (None, 17, 145, 8)   24          incresA_2b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_2conv2dbn (BatchNor (None, 17, 145, 12)  36          incresA_2b2_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b1_1conv2dact (Activat (None, 17, 145, 8)   0           incresA_2b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_2conv2dact (Activat (None, 17, 145, 12)  0           incresA_2b2_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b0conv2d (Conv2D)      (None, 17, 145, 8)   768         incresA_1act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b1_2conv2d (Conv2D)    (None, 17, 145, 32)  2304        incresA_2b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_3conv2d (Conv2D)    (None, 17, 145, 16)  1728        incresA_2b2_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b0conv2dbn (BatchNorma (None, 17, 145, 8)   24          incresA_2b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b1_2conv2dbn (BatchNor (None, 17, 145, 32)  96          incresA_2b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_3conv2dbn (BatchNor (None, 17, 145, 16)  48          incresA_2b2_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b0conv2dact (Activatio (None, 17, 145, 8)   0           incresA_2b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b1_2conv2dact (Activat (None, 17, 145, 32)  0           incresA_2b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2b2_3conv2dact (Activat (None, 17, 145, 16)  0           incresA_2b2_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2_concat (Concatenate)  (None, 17, 145, 56)  0           incresA_2b0conv2dact[0][0]       \n",
      "                                                                 incresA_2b1_2conv2dact[0][0]     \n",
      "                                                                 incresA_2b2_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2filt_exp_1x1conv2d (Co (None, 17, 145, 96)  5376        incresA_2_concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "incresA_2filt_exp_1x1conv2dbn ( (None, 17, 145, 96)  288         incresA_2filt_exp_1x1conv2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "incresA_2act_scaling (Lambda)   (None, 17, 145, 96)  0           incresA_1act_scaling[0][0]       \n",
      "                                                                 incresA_2filt_exp_1x1conv2dbn[0][\n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b2_1conv2d (Conv2D)    (None, 17, 145, 8)   768         incresA_2act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b2_1conv2dbn (BatchNor (None, 17, 145, 8)   24          incresA_3b2_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b2_1conv2dact (Activat (None, 17, 145, 8)   0           incresA_3b2_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b1_1conv2d (Conv2D)    (None, 17, 145, 8)   768         incresA_2act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b2_2conv2d (Conv2D)    (None, 17, 145, 12)  864         incresA_3b2_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b1_1conv2dbn (BatchNor (None, 17, 145, 8)   24          incresA_3b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b2_2conv2dbn (BatchNor (None, 17, 145, 12)  36          incresA_3b2_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b1_1conv2dact (Activat (None, 17, 145, 8)   0           incresA_3b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b2_2conv2dact (Activat (None, 17, 145, 12)  0           incresA_3b2_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b0conv2d (Conv2D)      (None, 17, 145, 8)   768         incresA_2act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b1_2conv2d (Conv2D)    (None, 17, 145, 32)  2304        incresA_3b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b2_3conv2d (Conv2D)    (None, 17, 145, 16)  1728        incresA_3b2_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b0conv2dbn (BatchNorma (None, 17, 145, 8)   24          incresA_3b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b1_2conv2dbn (BatchNor (None, 17, 145, 32)  96          incresA_3b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b2_3conv2dbn (BatchNor (None, 17, 145, 16)  48          incresA_3b2_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b0conv2dact (Activatio (None, 17, 145, 8)   0           incresA_3b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b1_2conv2dact (Activat (None, 17, 145, 32)  0           incresA_3b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3b2_3conv2dact (Activat (None, 17, 145, 16)  0           incresA_3b2_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3_concat (Concatenate)  (None, 17, 145, 56)  0           incresA_3b0conv2dact[0][0]       \n",
      "                                                                 incresA_3b1_2conv2dact[0][0]     \n",
      "                                                                 incresA_3b2_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3filt_exp_1x1conv2d (Co (None, 17, 145, 96)  5376        incresA_3_concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "incresA_3filt_exp_1x1conv2dbn ( (None, 17, 145, 96)  288         incresA_3filt_exp_1x1conv2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "incresA_3act_scaling (Lambda)   (None, 17, 145, 96)  0           incresA_2act_scaling[0][0]       \n",
      "                                                                 incresA_3filt_exp_1x1conv2dbn[0][\n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_1conv2d (Conv2D)      (None, 17, 145, 64)  6144        incresA_3act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_1conv2dbn (BatchNorma (None, 17, 145, 64)  192         x_red1_c2_1conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_1conv2dact (Activatio (None, 17, 145, 64)  0           x_red1_c2_1conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_2conv2d (Conv2D)      (None, 17, 145, 64)  36864       x_red1_c2_1conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_2conv2dbn (BatchNorma (None, 17, 145, 64)  192         x_red1_c2_2conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_2conv2dact (Activatio (None, 17, 145, 64)  0           x_red1_c2_2conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c1conv2d (Conv2D)        (None, 8, 72, 96)    82944       incresA_3act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_3conv2d (Conv2D)      (None, 8, 72, 96)    55296       x_red1_c2_2conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c1conv2dbn (BatchNormali (None, 8, 72, 96)    288         x_red1_c1conv2d[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_3conv2dbn (BatchNorma (None, 8, 72, 96)    288         x_red1_c2_3conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "red_maxpool_1 (MaxPooling2D)    (None, 8, 72, 96)    0           incresA_3act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c1conv2dact (Activation) (None, 8, 72, 96)    0           x_red1_c1conv2dbn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "x_red1_c2_3conv2dact (Activatio (None, 8, 72, 96)    0           x_red1_c2_3conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "red_concat_1 (Concatenate)      (None, 8, 72, 288)   0           red_maxpool_1[0][0]              \n",
      "                                                                 x_red1_c1conv2dact[0][0]         \n",
      "                                                                 x_red1_c2_3conv2dact[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_1conv2d (Conv2D)    (None, 8, 72, 32)    9216        red_concat_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_1conv2dbn (BatchNor (None, 8, 72, 32)    96          incresB_1b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_1conv2dact (Activat (None, 8, 72, 32)    0           incresB_1b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_2conv2d (Conv2D)    (None, 8, 72, 40)    8960        incresB_1b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_2conv2dbn (BatchNor (None, 8, 72, 40)    120         incresB_1b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_2conv2dact (Activat (None, 8, 72, 40)    0           incresB_1b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b0conv2d (Conv2D)      (None, 8, 72, 48)    13824       red_concat_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_3conv2d (Conv2D)    (None, 8, 72, 48)    13440       incresB_1b1_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b0conv2dbn (BatchNorma (None, 8, 72, 48)    144         incresB_1b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_3conv2dbn (BatchNor (None, 8, 72, 48)    144         incresB_1b1_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b0conv2dact (Activatio (None, 8, 72, 48)    0           incresB_1b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1b1_3conv2dact (Activat (None, 8, 72, 48)    0           incresB_1b1_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1_mixed (Concatenate)   (None, 8, 72, 96)    0           incresB_1b0conv2dact[0][0]       \n",
      "                                                                 incresB_1b1_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1filt_exp_1x1conv2d (Co (None, 8, 72, 288)   27648       incresB_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "incresB_1filt_exp_1x1conv2dbn ( (None, 8, 72, 288)   864         incresB_1filt_exp_1x1conv2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "incresB_1act_scaling (Lambda)   (None, 8, 72, 288)   0           red_concat_1[0][0]               \n",
      "                                                                 incresB_1filt_exp_1x1conv2dbn[0][\n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_1conv2d (Conv2D)    (None, 8, 72, 32)    9216        incresB_1act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_1conv2dbn (BatchNor (None, 8, 72, 32)    96          incresB_2b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_1conv2dact (Activat (None, 8, 72, 32)    0           incresB_2b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_2conv2d (Conv2D)    (None, 8, 72, 40)    8960        incresB_2b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_2conv2dbn (BatchNor (None, 8, 72, 40)    120         incresB_2b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_2conv2dact (Activat (None, 8, 72, 40)    0           incresB_2b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b0conv2d (Conv2D)      (None, 8, 72, 48)    13824       incresB_1act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_3conv2d (Conv2D)    (None, 8, 72, 48)    13440       incresB_2b1_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b0conv2dbn (BatchNorma (None, 8, 72, 48)    144         incresB_2b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_3conv2dbn (BatchNor (None, 8, 72, 48)    144         incresB_2b1_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b0conv2dact (Activatio (None, 8, 72, 48)    0           incresB_2b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2b1_3conv2dact (Activat (None, 8, 72, 48)    0           incresB_2b1_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2_mixed (Concatenate)   (None, 8, 72, 96)    0           incresB_2b0conv2dact[0][0]       \n",
      "                                                                 incresB_2b1_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2filt_exp_1x1conv2d (Co (None, 8, 72, 288)   27648       incresB_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "incresB_2filt_exp_1x1conv2dbn ( (None, 8, 72, 288)   864         incresB_2filt_exp_1x1conv2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "incresB_2act_scaling (Lambda)   (None, 8, 72, 288)   0           incresB_1act_scaling[0][0]       \n",
      "                                                                 incresB_2filt_exp_1x1conv2dbn[0][\n",
      "__________________________________________________________________________________________________\n",
      "incresB_3b1_1conv2d (Conv2D)    (None, 8, 72, 32)    9216        incresB_2act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3b1_1conv2dbn (BatchNor (None, 8, 72, 32)    96          incresB_3b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3b1_1conv2dact (Activat (None, 8, 72, 32)    0           incresB_3b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3b1_2conv2d (Conv2D)    (None, 8, 72, 40)    8960        incresB_3b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3b1_2conv2dbn (BatchNor (None, 8, 72, 40)    120         incresB_3b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3b1_2conv2dact (Activat (None, 8, 72, 40)    0           incresB_3b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3b0conv2d (Conv2D)      (None, 8, 72, 48)    13824       incresB_2act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3b1_3conv2d (Conv2D)    (None, 8, 72, 48)    13440       incresB_3b1_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3b0conv2dbn (BatchNorma (None, 8, 72, 48)    144         incresB_3b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3b1_3conv2dbn (BatchNor (None, 8, 72, 48)    144         incresB_3b1_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3b0conv2dact (Activatio (None, 8, 72, 48)    0           incresB_3b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3b1_3conv2dact (Activat (None, 8, 72, 48)    0           incresB_3b1_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3_mixed (Concatenate)   (None, 8, 72, 96)    0           incresB_3b0conv2dact[0][0]       \n",
      "                                                                 incresB_3b1_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3filt_exp_1x1conv2d (Co (None, 8, 72, 288)   27648       incresB_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "incresB_3filt_exp_1x1conv2dbn ( (None, 8, 72, 288)   864         incresB_3filt_exp_1x1conv2d[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "incresB_3act_scaling (Lambda)   (None, 8, 72, 288)   0           incresB_2act_scaling[0][0]       \n",
      "                                                                 incresB_3filt_exp_1x1conv2dbn[0][\n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c31conv2d (Conv2D)       (None, 8, 72, 64)    18432       incresB_3act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c31conv2dbn (BatchNormal (None, 8, 72, 64)    192         x_red2_c31conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c31conv2dact (Activation (None, 8, 72, 64)    0           x_red2_c31conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c11conv2d (Conv2D)       (None, 8, 72, 64)    18432       incresB_3act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c21conv2d (Conv2D)       (None, 8, 72, 64)    18432       incresB_3act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c32conv2d (Conv2D)       (None, 8, 72, 64)    36864       x_red2_c31conv2dact[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c11conv2dbn (BatchNormal (None, 8, 72, 64)    192         x_red2_c11conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c21conv2dbn (BatchNormal (None, 8, 72, 64)    192         x_red2_c21conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c32conv2dbn (BatchNormal (None, 8, 72, 64)    192         x_red2_c32conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c11conv2dact (Activation (None, 8, 72, 64)    0           x_red2_c11conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c21conv2dact (Activation (None, 8, 72, 64)    0           x_red2_c21conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c32conv2dact (Activation (None, 8, 72, 64)    0           x_red2_c32conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c12conv2d (Conv2D)       (None, 3, 35, 96)    55296       x_red2_c11conv2dact[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c22conv2d (Conv2D)       (None, 3, 35, 64)    36864       x_red2_c21conv2dact[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c33conv2d (Conv2D)       (None, 3, 35, 64)    36864       x_red2_c32conv2dact[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c12conv2dbn (BatchNormal (None, 3, 35, 96)    288         x_red2_c12conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c22conv2dbn (BatchNormal (None, 3, 35, 64)    192         x_red2_c22conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c33conv2dbn (BatchNormal (None, 3, 35, 64)    192         x_red2_c33conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "red_maxpool_2 (MaxPooling2D)    (None, 3, 35, 288)   0           incresB_3act_scaling[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c12conv2dact (Activation (None, 3, 35, 96)    0           x_red2_c12conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c22conv2dact (Activation (None, 3, 35, 64)    0           x_red2_c22conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x_red2_c33conv2dact (Activation (None, 3, 35, 64)    0           x_red2_c33conv2dbn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "red_concat_2 (Concatenate)      (None, 3, 35, 512)   0           red_maxpool_2[0][0]              \n",
      "                                                                 x_red2_c12conv2dact[0][0]        \n",
      "                                                                 x_red2_c22conv2dact[0][0]        \n",
      "                                                                 x_red2_c33conv2dact[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_1conv2d (Conv2D)    (None, 3, 35, 48)    24576       red_concat_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_1conv2dbn (BatchNor (None, 3, 35, 48)    144         incresC_1b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_1conv2dact (Activat (None, 3, 35, 48)    0           incresC_1b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_2conv2d (Conv2D)    (None, 3, 35, 56)    8064        incresC_1b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_2conv2dbn (BatchNor (None, 3, 35, 56)    168         incresC_1b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_2conv2dact (Activat (None, 3, 35, 56)    0           incresC_1b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b0conv2d (Conv2D)      (None, 3, 35, 48)    24576       red_concat_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_3conv2d (Conv2D)    (None, 3, 35, 64)    10752       incresC_1b1_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b0conv2dbn (BatchNorma (None, 3, 35, 48)    144         incresC_1b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_3conv2dbn (BatchNor (None, 3, 35, 64)    192         incresC_1b1_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b0conv2dact (Activatio (None, 3, 35, 48)    0           incresC_1b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1b1_3conv2dact (Activat (None, 3, 35, 64)    0           incresC_1b1_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1_mixed (Concatenate)   (None, 3, 35, 112)   0           incresC_1b0conv2dact[0][0]       \n",
      "                                                                 incresC_1b1_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1fin1x1conv2d (Conv2D)  (None, 3, 35, 512)   57344       incresC_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1fin1x1conv2dbn (BatchN (None, 3, 35, 512)   1536        incresC_1fin1x1conv2d[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_1act_saling (Lambda)    (None, 3, 35, 512)   0           red_concat_2[0][0]               \n",
      "                                                                 incresC_1fin1x1conv2dbn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_1conv2d (Conv2D)    (None, 3, 35, 48)    24576       incresC_1act_saling[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_1conv2dbn (BatchNor (None, 3, 35, 48)    144         incresC_2b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_1conv2dact (Activat (None, 3, 35, 48)    0           incresC_2b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_2conv2d (Conv2D)    (None, 3, 35, 56)    8064        incresC_2b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_2conv2dbn (BatchNor (None, 3, 35, 56)    168         incresC_2b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_2conv2dact (Activat (None, 3, 35, 56)    0           incresC_2b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b0conv2d (Conv2D)      (None, 3, 35, 48)    24576       incresC_1act_saling[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_3conv2d (Conv2D)    (None, 3, 35, 64)    10752       incresC_2b1_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b0conv2dbn (BatchNorma (None, 3, 35, 48)    144         incresC_2b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_3conv2dbn (BatchNor (None, 3, 35, 64)    192         incresC_2b1_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b0conv2dact (Activatio (None, 3, 35, 48)    0           incresC_2b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2b1_3conv2dact (Activat (None, 3, 35, 64)    0           incresC_2b1_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2_mixed (Concatenate)   (None, 3, 35, 112)   0           incresC_2b0conv2dact[0][0]       \n",
      "                                                                 incresC_2b1_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2fin1x1conv2d (Conv2D)  (None, 3, 35, 512)   57344       incresC_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2fin1x1conv2dbn (BatchN (None, 3, 35, 512)   1536        incresC_2fin1x1conv2d[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_2act_saling (Lambda)    (None, 3, 35, 512)   0           incresC_1act_saling[0][0]        \n",
      "                                                                 incresC_2fin1x1conv2dbn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3b1_1conv2d (Conv2D)    (None, 3, 35, 48)    24576       incresC_2act_saling[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3b1_1conv2dbn (BatchNor (None, 3, 35, 48)    144         incresC_3b1_1conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3b1_1conv2dact (Activat (None, 3, 35, 48)    0           incresC_3b1_1conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3b1_2conv2d (Conv2D)    (None, 3, 35, 56)    8064        incresC_3b1_1conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3b1_2conv2dbn (BatchNor (None, 3, 35, 56)    168         incresC_3b1_2conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3b1_2conv2dact (Activat (None, 3, 35, 56)    0           incresC_3b1_2conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3b0conv2d (Conv2D)      (None, 3, 35, 48)    24576       incresC_2act_saling[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3b1_3conv2d (Conv2D)    (None, 3, 35, 64)    10752       incresC_3b1_2conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3b0conv2dbn (BatchNorma (None, 3, 35, 48)    144         incresC_3b0conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3b1_3conv2dbn (BatchNor (None, 3, 35, 64)    192         incresC_3b1_3conv2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3b0conv2dact (Activatio (None, 3, 35, 48)    0           incresC_3b0conv2dbn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3b1_3conv2dact (Activat (None, 3, 35, 64)    0           incresC_3b1_3conv2dbn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3_mixed (Concatenate)   (None, 3, 35, 112)   0           incresC_3b0conv2dact[0][0]       \n",
      "                                                                 incresC_3b1_3conv2dact[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3fin1x1conv2d (Conv2D)  (None, 3, 35, 512)   57344       incresC_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3fin1x1conv2dbn (BatchN (None, 3, 35, 512)   1536        incresC_3fin1x1conv2d[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "incresC_3act_saling (Lambda)    (None, 3, 35, 512)   0           incresC_2act_saling[0][0]        \n",
      "                                                                 incresC_3fin1x1conv2dbn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           incresC_3act_saling[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            2052        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,116,860\n",
      "Trainable params: 1,106,660\n",
      "Non-trainable params: 10,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = sp.GetPieceSize()+1 #embedding_matrix.shape[0]\n",
    "MAXSEQLEN = X_toks_train.shape[1]\n",
    "# MAXCHARSLEN = X_train.shape[1]\n",
    "REPEAT=5\n",
    "EMBVECSIZE=300\n",
    "\n",
    "model = get_model(vocab_size = VOCAB_SIZE,\n",
    "                  emb_vec_size=EMBVECSIZE,\n",
    "                  repeat=REPEAT,\n",
    "                  n_classes=len(chars), \n",
    "                  seq_len_emb=MAXSEQLEN, \n",
    "                  seq_len_chars=None)\n",
    "\n",
    "optimizer = Adam(lr=1e-3, decay=1e-4)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we wanna use Embedding Matrix with FT vectors then one should uncomment the following lines-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding = model.get_layer('BPE_emb')\n",
    "embedding.set_weights([embedding_matrix])\n",
    "embedding.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Training: Load Model from the last Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './models/keras/inseption_resnet_emb_fasttext.h5'\n",
    "model = load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-4, decay=0.)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2166337 samples, validate on 382295 samples\n",
      "Epoch 1/200\n",
      "  57600/2166337 [..............................] - ETA: 1:40:04 - loss: 1.3455 - acc: 0.3389"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0c4fa06606bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m history = model.fit(X_toks_train, y_train, batch_size=BATCH_SIZE, epochs=n_epoch, shuffle=True,\n\u001b[0;32m---> 11\u001b[0;31m                     validation_split=0.15, verbose=1, callbacks=callbacks).history\n\u001b[0m",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/PYENV.GPUAI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = './models/keras/inseption_resnet_emb_fasttext.h5'\n",
    "\n",
    "callbacks = [EarlyStopping(patience=12, monitor='acc'),\n",
    "             ModelCheckpoint(path, monitor='acc', verbose=1, save_best_only=True),\n",
    "             ReduceLROnPlateau(monitor='acc', factor=1e-5, patience=3, verbose=1)]\n",
    "\n",
    "BATCH_SIZE=256\n",
    "n_epoch=200\n",
    "\n",
    "history = model.fit(X_toks_train, y_train, batch_size=BATCH_SIZE, epochs=n_epoch, shuffle=True,\n",
    "                    validation_split=0.15, verbose=1, callbacks=callbacks).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOB Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict([X_toks_test, X_test])\n",
    "y_pred = y_pred.argmax(axis=-1)\n",
    "\n",
    "y_true = y_test.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3 (GPUAI)",
   "language": "python",
   "name": "python36_gpuai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
